ylab = "BIC",
type = "l",
xlim = c(1, 8)
)
fit.fwd = regsubsets(Y ~ poly(X, 10), data = df, method = "forward")
res.fwd = summary(fit.fwd)
stat.fwd = cbind(res.fwd$adjr2,
res.fwd$cp,
res.fwd$bic)
colnames(stat.fwd) = c("Adjr2", "Cp", "BIC")
stat.fwd
par(mfrow = c(2, 2))
plot(
res.fwd$cp,
xlab = "# of Var",
ylab = "CP",
type = "l",
xlim = c(1, 8)
)
plot(
res.fwd$adjr2,
xlab = "# of Var",
ylab = "ADJR^2",
type = "l",
xlim = c(1, 8)
)
plot(
res.fwd$bic,
xlab = "# of Var",
ylab = "BIC",
type = "l",
xlim = c(1, 8)
)
fit.bwd = regsubsets(Y ~ poly(X, 10), data = df, method = "backward")
res.bwd = summary(fit.bwd)
stat.bwd = cbind(res.bwd$adjr2,
res.bwd$cp,
res.bwd$bic)
colnames(stat.bwd) = c("Adjr2", "Cp", "BIC")
stat.bwd
par(mfrow = c(2, 2))
plot(
res.bwd$cp,
xlab = "# of Var",
ylab = "CP",
type = "l",
xlim = c(1, 8)
)
plot(
res.bwd$adjr2,
xlab = "# of Var",
ylab = "ADJR^2",
type = "l",
xlim = c(1, 8)
)
plot(
res.bwd$bic,
xlab = "# of Var",
ylab = "BIC",
type = "l",
xlim = c(1, 8)
)
print(predicted * 1000)
print(predicted)
iq = 110
gpa = 4
predicted = 85 +  10 * gpa +  0.07 * iq +  0.01 * (gpa * iq)
print(predicted)
print(predicted * 1000)
stat[3]
stat[, 3]
stat[3]
stat[3,]
fit.fwd = regsubsets(Y ~ poly(X, 10), data = df, method = "forward")
res.fwd = summary(fit.fwd)
stat.fwd = cbind(res.fwd$adjr2,
res.fwd$cp,
res.fwd$bic)
colnames(stat.fwd) = c("Adjr2", "Cp", "BIC")
stat.fwd
stat.fwd[3,]
par(mfrow = c(2, 2))
plot(
res.fwd$cp,
xlab = "# of Var",
ylab = "CP",
type = "l",
xlim = c(1, 8)
)
plot(
res.fwd$adjr2,
xlab = "# of Var",
ylab = "ADJR^2",
type = "l",
xlim = c(1, 8)
)
plot(
res.fwd$bic,
xlab = "# of Var",
ylab = "BIC",
type = "l",
xlim = c(1, 8)
)
library(ssh)
install.packages("ssh")
library(ssh)
library(ssh)
ssh_connect("cosc0231@code.cs.uh.edu")
library(ssh)
session = ssh_connect("cosc0231@code.cs.uh.edu")
ssh_exec_wait(session, command = 'whoami')
ssh_exec_wait(session, command = 'ls')
ssh_exec_wait(session, command = 'python3 ./hw2/checkdb.py')
ssh_exec_wait(session, command = 'python3 ./hw2/checkdb.py' database='dbxyz.txt')
ssh_exec_wait(session, command = 'python3 ./hw2/checkdb.py' 'database=dbxyz.txt')
ssh_exec_wait(session, command = 'python3 ./hw2/checkdb.py database=dbxyz.txt')
ssh_exec_wait(session, command = 'ls ./hw2/')
ssh_exec_wait(session, command = 'python3 ./hw2/checkdb.py database=dbxyz.txt')
ssh_exec_wait(session, command = 'ls ./hw2/')
ssh_exec_wait(session, command = 'python3 connectqry_example.py')
ssh_exec_wait(session, command = 'python3 ./hw2/connectqry_example.py')
uhcosc3380swag
\
ssh_exec_wait(session, command = 'ls ./hw2/')
ssh_exec_wait(session, command = 'python3 ./hw2/hw2_test_connection.py')
uhcosc3380swag
ssh_exec_wait(session, command = c('python3', '. / hw2 / hw2_test_connection.py'))
ssh_exec_wait(session, command = c('python3', './hw2/hw2_test_connection.py'))
ssh_exec_wait(session, command = c('python3 ./hw2/hw2_test_connection.py'
))
ssh_exec_wait(session, command = c('python3'))
ssh_exec_wait(session, command = 'python3')
a
sa
ssh_exec_wait(session, command = 'psql -d COSC3380')
library(ssh)
session = ssh_connect("cosc0231@code.cs.uh.edu")
ssh_exec_wait(session, command = 'ls ./hw2/')
ssh_exec_wait(session, command = 'psql -d COSC3380')
ssh_exec_wait(session, command = 'pwd')
reticulate::repl_python()
pip
library(ssh)
session = ssh_connect("cosc0231@code.cs.uh.edu")
ssh_exec_wait(session, command = 'pwd')
whoami
ssh_exec_wait(session, command = 'pwd')
ssh_exec_wait(session, scriot)
ssh_exec_wait(session, command = 'pwd')
ssh_exec_wait(session, command = 'psql -d COSC3380')
x = 2+2
x
print("hello")
iq = 110
gpa = 4
predicted = 85 +  10 * gpa +  0.07 * iq +  0.01 * (gpa * iq)
print(predicted)
print(predicted * 1000)
library(ISLR)
Auto.lm = lm(mpg ~ horsepower, data = Auto)
summary(Auto.lm)
predict(Auto.lm, data.frame(horsepower = 98))
predict(Auto.lm, data.frame(horsepower = 98), interval = "p")
predict(Auto.lm, data.frame(horsepower = c(98)), interval = "c")
plot(Auto$horsepower, Auto$mpg)
abline(Auto.lm, lwd = 3, col = "red")
par(mfrow = c(2, 2))
plot(Auto.lm)
library(ISLR)
pairs(Auto)
Auto.clean = Auto[, 1:8]
cor(Auto.clean)
plot(Auto)
Auto.clean.mlm = lm(Auto.clean$mpg ~ ., data = Auto.clean)
summary(Auto.clean.mlm)
Auto.clean.mlms = lm(Auto.clean$mpg ~ ., data = Auto.clean[, c(3, 5, 7, 8)])
summary(Auto.clean.mlms)
par(mfrow = c(2, 2))
plot(Auto.clean.mlms)
plot(Auto.clean.mlm)
Auto.clean.mlmi = lm(
Auto.clean$mpg ~ .
+ displacement * horsepower
+ cylinders * acceleration
+ weight:displacement,
data = Auto.clean
)
summary(Auto.clean.mlmi)
pairs(log(Auto.clean))
pairs(sqrt(Auto.clean))
pairs((Auto.clean) ^ 2)
set.seed (1)
x1 = runif (100)
x2 = 0.5 * x1 + rnorm (100) / 10
y = 2 + 2 * x1 + 0.3 * x2 + rnorm (100)
cor(x1, x2)
par(mfrow = c(1, 1))
plot(x1, x2)
y.lm = lm(y ~ x1 + x2)
summary(y.lm)
yx1.lm = lm(y ~ x1)
summary(yx1.lm)
yx2.lm = lm(y ~ x2)
summary(yx2.lm)
x1 = c(x1 , 0.1)
x2 = c(x2 , 0.8)
y = c(y, 6)
y.lm2 = lm(y ~ x1 + x2)
summary(y.lm2)
par(mfrow = c(2, 2))
plot(y.lm2)
yx1.2.lm = lm(y ~ x1)
summary(yx1.2.lm)
par(mfrow = c(2, 2))
plot(yx1.2.lm)
yx2.2.lm = lm(y ~ x2)
summary(yx2.2.lm)
par(mfrow = c(2, 2))
plot(yx2.2.lm)
set.seed(1)
X <- rnorm(100)
noise <- rnorm(100)
Y <- 1 + 9 * X + 3 * X ^ 2 - 1 * X ^ 3 + noise
df <- data.frame(Y, X)
library(leaps)
fit = regsubsets(Y ~ poly(X, 10), data = df)
res = summary(fit)
stat = cbind(res$adjr2,
res$cp,
res$bic)
colnames(stat) = c("Adjr2", "Cp", "BIC")
stat
stat[3,]
par(mfrow = c(2, 2))
plot(
res$cp,
xlab = "# of Var",
ylab = "CP",
type = "l",
xlim = c(1, 8)
)
plot(
res$adjr2,
xlab = "# of Var",
ylab = "ADJR^2",
type = "l",
xlim = c(1, 8)
)
plot(
res$bic,
xlab = "# of Var",
ylab = "BIC",
type = "l",
xlim = c(1, 8)
)
fit.fwd = regsubsets(Y ~ poly(X, 10), data = df, method = "forward")
res.fwd = summary(fit.fwd)
stat.fwd = cbind(res.fwd$adjr2,
res.fwd$cp,
res.fwd$bic)
colnames(stat.fwd) = c("Adjr2", "Cp", "BIC")
stat.fwd
stat.fwd[3,]
par(mfrow = c(2, 2))
plot(
res.fwd$cp,
xlab = "# of Var",
ylab = "CP",
type = "l",
xlim = c(1, 8)
)
plot(
res.fwd$adjr2,
xlab = "# of Var",
ylab = "ADJR^2",
type = "l",
xlim = c(1, 8)
)
plot(
res.fwd$bic,
xlab = "# of Var",
ylab = "BIC",
type = "l",
xlim = c(1, 8)
)
fit.bwd = regsubsets(Y ~ poly(X, 10), data = df, method = "backward")
res.bwd = summary(fit.bwd)
stat.bwd = cbind(res.bwd$adjr2,
res.bwd$cp,
res.bwd$bic)
colnames(stat.bwd) = c("Adjr2", "Cp", "BIC")
stat.bwd
stat.bwd[3,]
par(mfrow = c(2, 2))
plot(
res.bwd$cp,
xlab = "# of Var",
ylab = "CP",
type = "l",
xlim = c(1, 8)
)
plot(
res.bwd$adjr2,
xlab = "# of Var",
ylab = "ADJR^2",
type = "l",
xlim = c(1, 8)
)
plot(
res.bwd$bic,
xlab = "# of Var",
ylab = "BIC",
type = "l",
xlim = c(1, 8)
)
fit.bwd = regsubsets(Y ~ poly(X, 10), data = df, nbest=1 method = "backward")
fit.bwd = regsubsets(Y ~ poly(X, 10), data = df, nbest=1, method = "backward")
fit.bwd = regsubsets(Y ~ poly(X, 10), data = df, nbest=1, method = "backward")
summary(fit.bwd)
fit.bwd = regsubsets(Y ~ poly(X, 10), data = df, method = "backward")
res.bwd = summary(fit.bwd)
fit.bwd = regsubsets(Y ~ poly(X, 10), data = df, method = "backward")
res.bwd = summary(fit.bwd)
stat.bwd = cbind(res.bwd$adjr2,
res.bwd$cp,
res.bwd$bic)
colnames(stat.bwd) = c("Adjr2", "Cp", "BIC")
stat.bwd
library(car)
Data <- read.csv("~/Desktop/machineLearning/data_science/code/dataPreprocessing/R/Data.csv")
View(Data)
source('~/Desktop/machineLearning/data_science/code/dataPreprocessing/R/dataPreprocessing.r', echo=TRUE)
# Importing the dataset
dataset = read.csv('Data.csv')
# Importing the dataset
dataset = read.csv('./Data.csv')
# Importing the dataset
dataset = read.csv('Data.csv')
# Importing the dataset
dataset = Data
head(Data)
#Encoding Dependent Variable
dataset$Purchased = factor(dataset$Purchased,
levels = c('No', 'Yes'),
labels = c(0, 1))
# Data Preprocessing
# Importing the dataset
dataset = Data
# Taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age),
ave(
dataset$Age,
FUN = function(x)
mean(x, na.rm = TRUE)
),
dataset$Age)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(
dataset$Salary,
FUN = function(x)
mean(x, na.rm = TRUE)
),
dataset$Salary)
# Encoding categorical data
dataset$Country = factor(
dataset$Country,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3)
)
#Encoding Dependent Variable
dataset$Purchased = factor(dataset$Purchased,
levels = c('No', 'Yes'),
labels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
test_set
set.seed(123)
split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
# Data Preprocessing
# Importing the dataset
dataset = Data
# Taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age),
ave(
dataset$Age,
FUN = function(x)
mean(x, na.rm = TRUE)
),
dataset$Age)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(
dataset$Salary,
FUN = function(x)
mean(x, na.rm = TRUE)
),
dataset$Salary)
# Encoding categorical data
dataset$Country = factor(
dataset$Country,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3)
)
#Encoding Dependent Variable
dataset$Purchased = factor(dataset$Purchased,
levels = c('No', 'Yes'),
labels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
# training_set = scale(training_set)
# test_set = scale(test_set)
dataset$Purchased
dataset
head(dataset)
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$DependentVariable, SplitRatio = 0.8)
split = sample.split(dataset$DependentVariable, SplitRatio = 2/3)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
training_set
test_set
setwd("~/Desktop/machineLearning/data_science/code/dataPreprocessing/R")
# Importing the dataset
dataset = read.csv('Data.csv')
head(dataset)
View(Data)
setwd("~/Desktop/machineLearning/data_science/code/dataPreprocessing/R")
# Taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age),
ave(
dataset$Age,
FUN = function(x) {
mean(x, na.rm = TRUE)
}
),
dataset$Age)
head(dataset)
dataset$Age
dataset$Age = ifelse(is.na(dataset$Age),
ave(
dataset$Age,
FUN = function(x) {
print(x)
mean(x, na.rm = TRUE)
}
),
dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
sapply(dataset$Age, mean),
dataset$Age)
dataset$Age
# Importing the dataset
dataset = read.csv('Data.csv')
head(dataset)
dataset
dataset$Age = ifelse(is.na(dataset$Age),
sapply(dataset$Age,mean),
dataset$Age)
dataaset
dataset
dataset$Age = ifelse(is.na(dataset$Age),
sapply(dataset$Age, mean(dataset$Age, na.rm = True)),
dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
sapply(dataset$Age, mean(dataset$Age, na.rm = TRUE)),
dataset$Age)
dataset$Age = ifelse(is.na(dataset$Age),
sapply(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset
# Importing the dataset
dataset = read.csv('Data.csv')
dataset
dataset$Age = ifelse(is.na(dataset$Age),
ave(
dataset$Age,
FUN = function(x)
mean(x, na.rm = TRUE)
),
dataset$Age)
dataset
{}
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = .8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
View(stock3.lm)
install.packages(c("rmarkdown", "xfun"))
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = .8)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
View(training_set)
View(test_set)
